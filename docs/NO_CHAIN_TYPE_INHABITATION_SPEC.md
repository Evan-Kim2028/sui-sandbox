# No-Chain Type Inhabitation Benchmark Spec (Local Bytecode Sandbox)

## Goal

Provide a robust, repeatable benchmark for **type inhabitation / call construction** on Sui Move packages **without publishing** to any network (mainnet/testnet/devnet) and without requiring funded accounts.

This specification describes the **Local Bytecode Sandbox**—a deterministic, offline Move VM environment. See [LOCAL_BYTECODE_SANDBOX.md](LOCAL_BYTECODE_SANDBOX.md) for architecture overview.

The benchmark should:

- Construct candidate PTBs (or single-call payloads) targeting real package ABIs.
- Validate candidates with strict, deterministic checks to minimize false positives.
- Optionally execute candidates in a fully local sandbox (Move VM harness) to further reduce false positives, still without RPC.

Non-goals:

- Proving economic correctness, authorization correctness, or real state interactions on-chain.
- Guaranteeing that a locally validated PTB will succeed against arbitrary real on-chain state.

## Definitions

- **Hit**: A candidate call/PTB that passes the benchmark’s validation gates.
- **Tier A (Preflight Hit)**: Passes bytecode- and serialization-based validation only.
- **Tier B (VM Hit)**: Passes Tier A, then passes a local Move VM execution harness under a controlled synthetic state.

## Why No-Chain

Publishing helper packages on-chain requires:

- Sui CLI + keystore management
- a funded address
- environment compatibility (arch, Docker, etc.)

These are strong blockers for research/academic workflows. The no-chain approach keeps the benchmark portable and deterministic.

## High-Level Architecture

### Inputs

1. **Target corpus**: Bytecode modules for packages under evaluation.
   - Source: local bytecode artifacts (e.g., `.mv` files) or previously downloaded on-chain bytecode.
2. **Helper package bytecode corpus (ephemeral)**: Generated per-run (or cached), used only as local dependencies.
   - Source: Move source generated by the agent, compiled locally into `.mv`.
3. **Benchmark configuration**: selects targets, constraints, and scoring.

### Outputs

- For each attempt:
  - constructed call spec / PTB spec
  - Tier A validation report
  - optional Tier B execution report
- Summary metrics:
  - hit rate, failure reasons distribution, and determinism checks.

## CLI Interface (Proposed)

To avoid flag bloat and clearly separate modes, the tool will use `clap` subcommands.

```bash
sui-move-interface-extractor benchmark-local \
  --target-corpus <DIR> \
  --output <FILE> \
  --tier-a-only \
  --restricted-state
```

- `benchmark-local`: The primary subcommand for this spec.
- `--target-corpus`: Path to the directory containing target `.mv` files.
- `--output`: Path to the JSONL output report.
- `--tier-a-only`: Skip Tier B execution (faster, but potentially more false positives).
- `--restricted-state`: Use a restricted set of mock objects for Tier B (see below).

## Pipeline Overview

### Step 0 — Corpus Preparation

Build an in-memory “module resolver” index from local bytecode:

- Map `(address, module_name)` → `CompiledModule` bytes
- Map type tags and structs to layouts derived from bytecode

Key requirement: resolution must be deterministic and complete for the target set.

### Step 1 — Candidate Generation

Given a target function signature:

- Choose concrete type arguments (if generic).
- Generate candidate values for `Pure` parameters.
- Generate placeholders for `Object` parameters (typed object refs).

The generator must only emit candidates for which it can construct BCS for `Pure` args.

### Step 2 — Tier A: Deterministic Preflight Validation

Tier A is designed to minimize false positives without any state.

#### A1. Bytecode-resolved call target

Validate against bytecode corpus:

- module exists
- function exists
- visibility allows invocation in the intended context
- type parameters count matches
- parameter types and return types are exactly resolved

#### A2. Full type/layout resolution

For each concrete type:

- resolve struct definitions through module resolver
- compute canonical layout (including generics substitutions)
- validate ability constraints (copy/drop/store/key), including phantom type params behavior

#### A3. BCS validity for pure args

For each `Pure` argument:

- encode value to bytes
- decode bytes using computed layout
- re-encode and ensure stable roundtrip

Any mismatch is a hard fail.

#### A4. Object-arg typing

For each `Object` argument:

- determine expected object type (e.g., `&mut T`, `&T`, `T` where `T: key`)
- ensure object kind matches (mutable/shared/owned where inferable)
- ensure type tag matches exactly

Existence/ownership is not validated at Tier A.

#### A5. Transaction consistency

Across the candidate PTB:

- all type arguments are consistent
- argument kinds match expected types (pure vs object)
- vector nesting and type args match

If the benchmark uses a “single call spec” instead of a full PTB, consistency checks still apply to that call.

### Step 3 — Tier B: Local VM Execution (Optional but Recommended)

Tier B reduces false positives by executing under a controlled local environment.

#### B1. Synthetic state harness

Provide minimal state required for common invocation patterns.

**Restricted Initial State**:
To minimize complexity, Tier B will initially support only a restricted set of mock objects. This ensures deterministic behavior and simplifies state generation.

Supported initial types:
- `0x2::coin::Coin<T>`: A standard coin object with a specific value.
- `0x2::object::UID`: Always required for any object.

Future expansions will handle arbitrary generic structs, but the baseline will focus on these high-frequency types.

- a fake sender address
- “mock” objects matching required key structs (typed object IDs)
- storage-backed global state mapping object IDs → serialized resources

Constraints:

- state generation must be deterministic and reproducible
- object contents must conform to bytecode layouts

#### B2. Execution harness

Execute the Move call(s) under Move VM:

- load modules from local resolver
- load/store resources via synthetic state
- execute entry function or internal function via a controlled adapter

Record:

- success vs abort
- abort code and location
- resource reads/writes summary

Tier B “hit” means execution succeeded (no abort).

### Step 4 — Scoring, Reporting, and Determinism

Each attempt produces:

- `status`: `tier_a_hit`, `tier_b_hit`, or `miss`
- `failure_stage`: A1/A2/A3/A4/A5/B1/B2
- `reason`: canonical reason string, stable across runs

Determinism requirements:

- identical inputs produce identical outputs (including ordering)
- all serialization uses canonical BCS rules
- all module resolution is stable and versioned

## Output Schema

The benchmark will output a JSONL file where each line corresponds to a single attempt.

```json
{
  "target_package": "0x...",
  "target_module": "module_name",
  "target_function": "function_name",
  "status": "tier_a_hit", // or "tier_b_hit", "miss"
  "failure_stage": "A3", // optional, if miss
  "failure_reason": "BCS roundtrip failed", // optional
  "tier_a_details": {
    "validation_time_ms": 12,
    "bcs_roundtrip_verified": true
  },
  "tier_b_details": { // optional
    "execution_success": false,
    "abort_code": 123,
    "gas_used": 1000
  }
}
```

## Caching Strategy

Because helper packages may be generated repeatedly:

- Cache compiled helper bytecode by content hash:
  - hash of Move source + compiler version + build flags
  - store `.mv` module bytes + computed interface JSON

Cache must be:

- content-addressed
- safe to delete
- never required for correctness

## Required Code Changes (Proposed)

### New Concepts

1. **Local bytecode corpus / module resolver**
   - Unified interface for: load module bytes, resolve structs, compute layouts.
2. **Tier A preflight validator**
   - Produces deterministic validation report.
3. **Tier B VM harness**
   - Executes calls using local modules and synthetic storage.
4. **Scoring + reporting**
   - Produces stable metrics and artifacts per-run.

### Dependencies

To support helper generation and Tier B execution, the following dependencies must be added to `Cargo.toml`:

- `move-compiler`: For compiling helper packages (source -> `.mv`).
- `move-vm-runtime`: For executing the Tier B harness.
- `move-vm-types`: For interacting with VM types.

These should be sourced from the `MystenLabs/sui` repository to ensure compatibility with `sui-sdk` and `move-binary-format`.

### Likely Areas in Repo

This repo already emphasizes bytecode-first extraction. The following areas are expected touch points:

- Rust: bytecode decoding, layout derivation, tx/payload construction, simulator hooks.
- Benchmark Python: candidate generation/orchestration and result bookkeeping.

Exact file paths should be determined during implementation by locating:

- existing interface extraction from `.mv`
- existing PTB schema and tx sim entrypoints

## Verification & Validation Plan

### Unit Tests (Tier A)

- Target resolution: module/function lookup, generic arity, param matching
- Layout derivation: generics substitution, abilities checks, nested vectors
- BCS roundtrip: encode/decode stability for supported primitive + struct layouts
- PTB consistency checks: mismatched type args rejected deterministically

### Unit/Integration Tests (Tier B)

- Minimal module executed successfully with synthetic state
- Expected aborts are classified correctly (abort code + location)
- Storage read/write behavior is deterministic

### Golden Tests

- A small curated set of bytecode modules and expected validation outputs
- Ensure stable ordering and canonical reason strings

### End-to-End Local Run

- Run benchmark with a small local corpus and helper bytecode generation
- Require:
  - Tier A hit rate > 0
  - Tier B hit rate > 0 (for targets that are VM-executable in synthetic state)
  - stable outputs across two identical runs

## Open Questions

1. What is the canonical “candidate format”? (full PTB vs single-call spec)
2. Which subset of Move/Sui semantics is required for Tier B to be meaningful?
3. How to represent and generate typed “object placeholders” for Tier A?
4. What are the minimum object/resource templates needed to make Tier B productive?

## Implementation Milestones

1. Build module resolver for local `.mv` corpus
2. Implement Tier A validator + stable reason taxonomy
3. Integrate candidate generation with Tier A scoring
4. Add Tier B VM harness for a minimal subset
5. Expand synthetic state templates and add golden tests
