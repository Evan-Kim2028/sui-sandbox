//! Task-oriented workflow commands.
//!
//! - `init`: scaffold reproducible flow templates
//! - `script` (`run-flow` alias): execute YAML-defined command steps deterministically
//! - `context` (`flow` alias): generic package->replay UX

use anyhow::{anyhow, Context, Result};
use base64::Engine;
use clap::{ArgAction, Args, Parser, Subcommand, ValueEnum};
use move_binary_format::CompiledModule;
use move_core_types::account_address::AccountAddress;
use serde::{Deserialize, Serialize};
use serde_json::json;
use std::fs;
use std::path::{Path, PathBuf};
use std::process::Command;
use std::time::{Instant, SystemTime, UNIX_EPOCH};

use super::fetch::{fetch_package_into_state, fetch_package_with_bytecodes_into_state};
use super::network::sandbox_home;
use super::replay::{FetchStrategy, ReplayCmd, ReplayHydrationArgs, ReplayProfile, ReplaySource};
use super::SandboxState;
use sui_sandbox_core::checkpoint_discovery::{
    build_walrus_client as core_build_walrus_client,
    discover_checkpoint_targets as core_discover_checkpoint_targets,
    resolve_replay_target_from_discovery as core_resolve_replay_target_from_discovery,
    DiscoverOutput as CoreDiscoverOutput, WalrusArchiveNetwork as CoreWalrusArchiveNetwork,
};
use sui_transport::walrus::WalrusClient;

#[derive(Parser, Debug)]
#[command(about = "Generic two-step package/replay context flow (flow alias)")]
pub struct FlowCli {
    #[command(subcommand)]
    command: FlowSubcommand,
}

#[derive(Subcommand, Debug)]
enum FlowSubcommand {
    /// Prepare a reusable package context (fetch package + deps)
    Prepare(FlowPrepareCmd),
    /// Replay a transaction with optional prepared context
    Replay(FlowReplayCmd),
    /// Run prepare + replay in one command
    Run(FlowRunCmd),
    /// Discover replay-ready digests + packages from checkpoints
    Discover(FlowDiscoverCmd),
}

#[derive(Args, Debug)]
pub struct FlowPrepareCmd {
    /// Root package id to prepare
    #[arg(long = "package-id")]
    pub package_id: String,

    /// Also fetch transitive dependencies (default: true)
    #[arg(long = "with-deps", default_value_t = true, action = ArgAction::Set)]
    pub with_deps: bool,

    /// Output context JSON path
    #[arg(long)]
    pub output: Option<PathBuf>,

    /// Overwrite existing context file
    #[arg(long, default_value_t = false)]
    pub force: bool,
}

#[derive(Args, Debug)]
pub struct FlowReplayCmd {
    /// Transaction digest to replay
    pub digest: Option<String>,

    /// Optional context file generated by `context prepare` (or `flow prepare`)
    #[arg(long)]
    pub context: Option<PathBuf>,

    /// Optional package id to fetch before replay (if --context is not provided)
    #[arg(long = "package-id")]
    pub package_id: Option<String>,

    /// Also fetch transitive dependencies when using --package-id (default: true)
    #[arg(long = "with-deps", default_value_t = true, action = ArgAction::Set)]
    pub with_deps: bool,

    /// Optional checkpoint override (recommended for walrus source)
    #[arg(long)]
    pub checkpoint: Option<u64>,

    /// Auto-discover a digest from latest N checkpoints (requires --context or --package-id)
    #[arg(long, conflicts_with_all = ["digest", "state_json", "checkpoint"])]
    pub discover_latest: Option<u64>,

    /// Walrus archive network used for --discover-latest
    #[arg(long, value_enum, default_value = "mainnet")]
    pub walrus_network: WalrusArchiveNetwork,

    /// Override Walrus caching endpoint (requires --walrus-aggregator-url)
    #[arg(long)]
    pub walrus_caching_url: Option<String>,

    /// Override Walrus aggregator endpoint (requires --walrus-caching-url)
    #[arg(long)]
    pub walrus_aggregator_url: Option<String>,

    /// Optional state JSON for deterministic custom replay input data
    #[arg(long = "state-json")]
    pub state_json: Option<PathBuf>,

    /// Replay hydration source
    #[arg(long, value_enum, default_value = "hybrid")]
    pub source: ReplaySource,

    /// Allow fallback hydration paths when data is missing
    #[arg(long = "allow-fallback", default_value_t = true, action = ArgAction::Set)]
    pub allow_fallback: bool,

    /// Prefetch depth for dynamic fields
    #[arg(long, default_value_t = 3)]
    pub prefetch_depth: usize,

    /// Prefetch limit per dynamic-field parent
    #[arg(long, default_value_t = 200)]
    pub prefetch_limit: usize,

    /// Disable dynamic-field prefetch
    #[arg(long, default_value_t = false)]
    pub no_prefetch: bool,

    /// Auto-inject system objects (Clock/Random) when missing
    #[arg(long, default_value_t = true, action = ArgAction::Set)]
    pub auto_system_objects: bool,

    /// Compare local replay against on-chain effects
    #[arg(long, default_value_t = false)]
    pub compare: bool,

    /// Hydration-only mode (skip VM execution and print replay-state summary)
    #[arg(long, default_value_t = false)]
    pub analyze_only: bool,

    /// VM-only mode (disable fallback paths)
    #[arg(long, default_value_t = false)]
    pub vm_only: bool,

    /// Fail command when replay output indicates mismatch/failure
    #[arg(long, default_value_t = false)]
    pub strict: bool,
}

#[derive(Args, Debug)]
pub struct FlowRunCmd {
    /// Root package id to prepare
    #[arg(long = "package-id")]
    pub package_id: String,

    /// Transaction digest to replay (optional when --state-json has a single state)
    #[arg(long)]
    pub digest: Option<String>,

    /// Also fetch transitive dependencies (default: true)
    #[arg(long = "with-deps", default_value_t = true, action = ArgAction::Set)]
    pub with_deps: bool,

    /// Optional path to persist context JSON (portable for later --context replay)
    #[arg(long = "context-out")]
    pub context_out: Option<PathBuf>,

    /// Overwrite existing context file when --context-out is used
    #[arg(long, default_value_t = false)]
    pub force: bool,

    /// Optional checkpoint override (recommended for walrus source)
    #[arg(long)]
    pub checkpoint: Option<u64>,

    /// Auto-discover a digest from latest N checkpoints for --package-id
    #[arg(long, conflicts_with_all = ["digest", "state_json", "checkpoint"])]
    pub discover_latest: Option<u64>,

    /// Walrus archive network used for --discover-latest
    #[arg(long, value_enum, default_value = "mainnet")]
    pub walrus_network: WalrusArchiveNetwork,

    /// Override Walrus caching endpoint (requires --walrus-aggregator-url)
    #[arg(long)]
    pub walrus_caching_url: Option<String>,

    /// Override Walrus aggregator endpoint (requires --walrus-caching-url)
    #[arg(long)]
    pub walrus_aggregator_url: Option<String>,

    /// Optional state JSON for deterministic custom replay input data
    #[arg(long = "state-json")]
    pub state_json: Option<PathBuf>,

    /// Replay hydration source
    #[arg(long, value_enum, default_value = "hybrid")]
    pub source: ReplaySource,

    /// Allow fallback hydration paths when data is missing
    #[arg(long = "allow-fallback", default_value_t = true, action = ArgAction::Set)]
    pub allow_fallback: bool,

    /// Prefetch depth for dynamic fields
    #[arg(long, default_value_t = 3)]
    pub prefetch_depth: usize,

    /// Prefetch limit per dynamic-field parent
    #[arg(long, default_value_t = 200)]
    pub prefetch_limit: usize,

    /// Disable dynamic-field prefetch
    #[arg(long, default_value_t = false)]
    pub no_prefetch: bool,

    /// Auto-inject system objects (Clock/Random) when missing
    #[arg(long, default_value_t = true, action = ArgAction::Set)]
    pub auto_system_objects: bool,

    /// Compare local replay against on-chain effects
    #[arg(long, default_value_t = false)]
    pub compare: bool,

    /// Hydration-only mode (skip VM execution and print replay-state summary)
    #[arg(long, default_value_t = false)]
    pub analyze_only: bool,

    /// VM-only mode (disable fallback paths)
    #[arg(long, default_value_t = false)]
    pub vm_only: bool,

    /// Fail command when replay output indicates mismatch/failure
    #[arg(long, default_value_t = false)]
    pub strict: bool,
}

#[derive(Args, Debug)]
pub struct FlowDiscoverCmd {
    /// Checkpoint spec: single (239615926), range (239615900..239615926), or list (239615900,239615910)
    #[arg(long, conflicts_with = "latest")]
    pub checkpoint: Option<String>,

    /// Scan latest N checkpoints (auto-discovers tip)
    #[arg(long, conflicts_with = "checkpoint")]
    pub latest: Option<u64>,

    /// Optional package filter (only include transactions touching this package)
    #[arg(long = "package-id")]
    pub package_id: Option<String>,

    /// Include framework packages (0x1/0x2/0x3) in results
    #[arg(long, default_value_t = false)]
    pub include_framework: bool,

    /// Max matching transactions to return
    #[arg(long, default_value_t = 200)]
    pub limit: usize,

    /// Walrus archive network for checkpoint discovery
    #[arg(long, value_enum, default_value = "mainnet")]
    pub walrus_network: WalrusArchiveNetwork,

    /// Override Walrus caching endpoint (requires --walrus-aggregator-url too)
    #[arg(long)]
    pub walrus_caching_url: Option<String>,

    /// Override Walrus aggregator endpoint (requires --walrus-caching-url too)
    #[arg(long)]
    pub walrus_aggregator_url: Option<String>,
}

#[derive(Debug, Clone, Copy, ValueEnum)]
pub enum WalrusArchiveNetwork {
    Mainnet,
    Testnet,
}

impl From<WalrusArchiveNetwork> for CoreWalrusArchiveNetwork {
    fn from(value: WalrusArchiveNetwork) -> Self {
        match value {
            WalrusArchiveNetwork::Mainnet => CoreWalrusArchiveNetwork::Mainnet,
            WalrusArchiveNetwork::Testnet => CoreWalrusArchiveNetwork::Testnet,
        }
    }
}

#[derive(Debug, Serialize, Deserialize)]
struct FlowContextFile {
    version: u32,
    package_id: String,
    with_deps: bool,
    rpc_url: String,
    generated_at_ms: u64,
    #[serde(default)]
    packages_fetched: Vec<String>,
    #[serde(default)]
    packages: serde_json::Value,
}

#[derive(Debug, Serialize, Deserialize, Clone)]
struct FlowContextPackage {
    address: String,
    #[serde(default)]
    modules: Vec<String>,
    #[serde(default)]
    bytecodes: Vec<String>,
}

type FlowDiscoverOutput = CoreDiscoverOutput;

impl FlowCli {
    pub async fn execute(
        &self,
        state: &mut SandboxState,
        json_output: bool,
        verbose: bool,
    ) -> Result<()> {
        match &self.command {
            FlowSubcommand::Prepare(cmd) => cmd.execute(state, json_output, verbose).await,
            FlowSubcommand::Replay(cmd) => cmd.execute(state, json_output, verbose).await,
            FlowSubcommand::Run(cmd) => cmd.execute(state, json_output, verbose).await,
            FlowSubcommand::Discover(cmd) => cmd.execute(json_output).await,
        }
    }
}

impl FlowPrepareCmd {
    pub(crate) async fn execute(
        &self,
        state: &mut SandboxState,
        json_output: bool,
        verbose: bool,
    ) -> Result<()> {
        let output_path = self
            .output
            .clone()
            .unwrap_or_else(|| default_flow_context_path(&self.package_id));

        let (context, packages_fetched) =
            prepare_context_data(state, &self.package_id, self.with_deps, verbose)?;
        write_context_file(&output_path, &context, self.force)?;

        if json_output {
            println!(
                "{}",
                serde_json::to_string_pretty(&json!({
                    "success": true,
                    "context_path": output_path,
                    "context_metadata": {
                        "version": context.version,
                        "package_id": context.package_id,
                        "with_deps": context.with_deps,
                        "rpc_url": context.rpc_url,
                        "generated_at_ms": context.generated_at_ms,
                    },
                    "packages_fetched_count": packages_fetched.len(),
                }))?
            );
        } else {
            println!("Flow context prepared:");
            println!("  package_id:   {}", self.package_id);
            println!("  with_deps:    {}", self.with_deps);
            println!("  packages:     {}", packages_fetched.len());
            println!("  context_path: {}", output_path.display());
            println!(
                "\nNext:\n  sui-sandbox context replay <DIGEST> --context {} --checkpoint <CP>",
                output_path.display()
            );
        }
        Ok(())
    }
}

impl FlowReplayCmd {
    pub(crate) async fn execute(
        &self,
        state: &mut SandboxState,
        json_output: bool,
        verbose: bool,
    ) -> Result<()> {
        if self.context.is_some() && self.package_id.is_some() {
            return Err(anyhow!(
                "Provide either --context or --package-id, not both"
            ));
        }

        let mut prepared_package: Option<(String, usize)> = None;
        if let Some(path) = self.context.as_ref() {
            let loaded = load_context_file_into_state(state, path, verbose)?;
            prepared_package = Some((loaded.package_id, loaded.packages_count));
        } else if let Some(package_id) = self.package_id.as_ref() {
            let fetched = fetch_package_into_state(state, package_id, self.with_deps, verbose)
                .with_context(|| format!("Failed to prefetch package {}", package_id))?;
            prepared_package = Some((package_id.clone(), fetched.packages_fetched.len()));
        }

        if !json_output {
            if let Some((pkg, count)) = prepared_package.as_ref() {
                println!("Prepared package context: {} ({} packages)", pkg, count);
            }
        }

        let (effective_digest, effective_checkpoint) = resolve_replay_target(
            self.digest.as_deref(),
            self.state_json.as_ref(),
            self.checkpoint,
            self.discover_latest,
            prepared_package.as_ref().map(|(pkg, _)| pkg.as_str()),
            self.walrus_network,
            self.walrus_caching_url.as_deref(),
            self.walrus_aggregator_url.as_deref(),
        )?;

        if !json_output {
            if let (Some(window), Some(digest), Some(checkpoint)) = (
                self.discover_latest,
                effective_digest.as_deref(),
                effective_checkpoint,
            ) {
                println!(
                    "Auto-discovered replay target: digest={} checkpoint={} (latest window: {})",
                    digest, checkpoint, window
                );
            }
        }

        let replay = ReplayCmd {
            digest: effective_digest,
            hydration: ReplayHydrationArgs {
                source: self.source,
                cache_dir: None,
                allow_fallback: self.allow_fallback,
                prefetch_depth: self.prefetch_depth,
                prefetch_limit: self.prefetch_limit,
                no_prefetch: self.no_prefetch,
                auto_system_objects: self.auto_system_objects,
            },
            profile: ReplayProfile::Balanced,
            vm_only: self.vm_only,
            strict: self.strict,
            compare: self.compare,
            analyze_only: self.analyze_only,
            verbose: false,
            fetch_strategy: FetchStrategy::Full,
            reconcile_dynamic_fields: true,
            synthesize_missing: false,
            self_heal_dynamic_fields: false,
            grpc_timeout_secs: 30,
            checkpoint: effective_checkpoint.map(|v| v.to_string()),
            state_json: self.state_json.clone(),
            export_state: None,
            latest: None,
        };

        replay.execute(state, json_output, verbose).await
    }
}

impl FlowRunCmd {
    pub(crate) async fn execute(
        &self,
        state: &mut SandboxState,
        json_output: bool,
        verbose: bool,
    ) -> Result<()> {
        let (effective_digest, effective_checkpoint) = resolve_replay_target(
            self.digest.as_deref(),
            self.state_json.as_ref(),
            self.checkpoint,
            self.discover_latest,
            Some(self.package_id.as_str()),
            self.walrus_network,
            self.walrus_caching_url.as_deref(),
            self.walrus_aggregator_url.as_deref(),
        )?;

        let (context, packages_fetched) =
            prepare_context_data(state, &self.package_id, self.with_deps, verbose)?;
        let context_path = if let Some(path) = self.context_out.as_ref() {
            write_context_file(path, &context, self.force)?;
            Some(path.display().to_string())
        } else {
            None
        };

        if !json_output {
            println!(
                "Prepared package context: {} ({} packages)",
                self.package_id,
                packages_fetched.len()
            );
            if let Some(path) = context_path.as_deref() {
                println!("Context written: {}", path);
            }
            if let (Some(window), Some(digest), Some(checkpoint)) = (
                self.discover_latest,
                effective_digest.as_deref(),
                effective_checkpoint,
            ) {
                println!(
                    "Auto-discovered replay target: digest={} checkpoint={} (latest window: {})",
                    digest, checkpoint, window
                );
            }
        }

        let replay = ReplayCmd {
            digest: effective_digest,
            hydration: ReplayHydrationArgs {
                source: self.source,
                cache_dir: None,
                allow_fallback: self.allow_fallback,
                prefetch_depth: self.prefetch_depth,
                prefetch_limit: self.prefetch_limit,
                no_prefetch: self.no_prefetch,
                auto_system_objects: self.auto_system_objects,
            },
            profile: ReplayProfile::Balanced,
            vm_only: self.vm_only,
            strict: self.strict,
            compare: self.compare,
            analyze_only: self.analyze_only,
            verbose: false,
            fetch_strategy: FetchStrategy::Full,
            reconcile_dynamic_fields: true,
            synthesize_missing: false,
            self_heal_dynamic_fields: false,
            grpc_timeout_secs: 30,
            checkpoint: effective_checkpoint.map(|v| v.to_string()),
            state_json: self.state_json.clone(),
            export_state: None,
            latest: None,
        };

        replay.execute(state, json_output, verbose).await
    }
}

impl FlowDiscoverCmd {
    pub(crate) async fn execute(&self, json_output: bool) -> Result<()> {
        let walrus = build_walrus_client(
            self.walrus_network,
            self.walrus_caching_url.as_deref(),
            self.walrus_aggregator_url.as_deref(),
        )?;
        let output = discover_flow_targets(
            &walrus,
            self.checkpoint.as_deref(),
            self.latest,
            self.package_id.as_deref(),
            self.include_framework,
            self.limit,
        )?;

        if json_output {
            println!("{}", serde_json::to_string_pretty(&output)?);
        } else {
            println!("Discovery summary:");
            println!("  checkpoints_scanned: {}", output.checkpoints_scanned);
            println!("  transactions_scanned: {}", output.transactions_scanned);
            println!("  ptbs_scanned: {}", output.ptbs_scanned);
            println!("  matches: {}", output.matches);
            if let Some(filter) = output.package_filter.as_deref() {
                println!("  package_filter: {}", filter);
            }
            if output.truncated {
                println!("  truncated: yes (increase --limit to see more)");
            }
            if output.targets.is_empty() {
                println!("No matching transactions found.");
            } else {
                println!("\nTargets:");
                for target in &output.targets {
                    println!(
                        "  cp={} digest={} sender={} packages={} calls={}",
                        target.checkpoint,
                        target.digest,
                        target.sender,
                        target.package_ids.join(","),
                        target.move_calls.len()
                    );
                }
            }
        }
        Ok(())
    }
}

#[allow(clippy::too_many_arguments)]
fn resolve_replay_target(
    digest: Option<&str>,
    state_json: Option<&PathBuf>,
    checkpoint: Option<u64>,
    discover_latest: Option<u64>,
    discover_package_id: Option<&str>,
    walrus_network: WalrusArchiveNetwork,
    walrus_caching_url: Option<&str>,
    walrus_aggregator_url: Option<&str>,
) -> Result<(Option<String>, Option<u64>)> {
    let walrus = build_walrus_client(walrus_network, walrus_caching_url, walrus_aggregator_url)?;
    core_resolve_replay_target_from_discovery(
        digest,
        checkpoint,
        state_json.is_some(),
        discover_latest,
        discover_package_id,
        &walrus,
    )
    .map_err(|err| {
        let message = err.to_string();
        if message == "digest cannot be empty" {
            anyhow!("--digest cannot be empty")
        } else if message
            == "provide digest, state_file, or discover_latest for replay target selection"
        {
            anyhow!("Provide --digest, --state-json, or --discover-latest for replay target selection")
        } else if message == "discover_package_id is required when discover_latest is set" {
            anyhow!(
                "--discover-latest requires package context; pass --package-id or --context with package_id"
            )
        } else {
            err
        }
    })
}

fn discover_flow_targets(
    walrus: &WalrusClient,
    checkpoint_spec: Option<&str>,
    latest: Option<u64>,
    package_id: Option<&str>,
    include_framework: bool,
    limit: usize,
) -> Result<FlowDiscoverOutput> {
    core_discover_checkpoint_targets(
        walrus,
        checkpoint_spec,
        latest,
        package_id,
        include_framework,
        limit,
    )
}

#[cfg(test)]
fn parse_checkpoint_spec(spec: &str) -> Result<Vec<u64>> {
    sui_sandbox_core::checkpoint_discovery::parse_checkpoint_spec(spec)
}

fn build_walrus_client(
    network: WalrusArchiveNetwork,
    caching_url: Option<&str>,
    aggregator_url: Option<&str>,
) -> Result<WalrusClient> {
    core_build_walrus_client(network.into(), caching_url, aggregator_url).map_err(|err| {
        let message = err.to_string();
        if message.contains("provide both walrus_caching_url and walrus_aggregator_url") {
            anyhow!("provide both --walrus-caching-url and --walrus-aggregator-url for custom endpoints")
        } else {
            err
        }
    })
}

#[derive(Parser, Debug)]
#[command(about = "Scaffold a task-oriented script template")]
pub struct InitCmd {
    /// Template name (currently: quickstart)
    #[arg(long, default_value = "quickstart")]
    pub example: String,

    /// Output directory for generated files
    #[arg(long, default_value = ".")]
    pub output_dir: PathBuf,

    /// Overwrite existing files
    #[arg(long, default_value_t = false)]
    pub force: bool,
}

#[derive(Parser, Debug)]
#[command(about = "Execute a YAML script file (run-flow alias)")]
pub struct RunFlowCmd {
    /// Path to flow YAML file
    pub flow_file: PathBuf,

    /// Print commands without executing
    #[arg(long, default_value_t = false)]
    pub dry_run: bool,

    /// Continue executing later steps even when one fails
    #[arg(long, default_value_t = false)]
    pub continue_on_error: bool,
}

#[derive(Debug, Deserialize)]
struct FlowFile {
    version: u32,
    name: Option<String>,
    description: Option<String>,
    steps: Vec<FlowStep>,
}

#[derive(Debug, Deserialize)]
struct FlowStep {
    name: Option<String>,
    command: Vec<String>,
    #[serde(default)]
    continue_on_error: bool,
}

#[derive(Debug, Serialize)]
struct FlowRunReport {
    flow_file: String,
    name: Option<String>,
    description: Option<String>,
    dry_run: bool,
    total_steps: usize,
    succeeded_steps: usize,
    failed_steps: usize,
    elapsed_ms: u128,
    steps: Vec<FlowStepReport>,
}

#[derive(Debug, Serialize, Clone)]
struct FlowStepReport {
    index: usize,
    name: Option<String>,
    command: Vec<String>,
    success: bool,
    exit_code: i32,
    elapsed_ms: u128,
    #[serde(skip_serializing_if = "Option::is_none")]
    error: Option<String>,
}

impl InitCmd {
    pub async fn execute(&self) -> Result<()> {
        if self.example != "quickstart" {
            return Err(anyhow!(
                "Unknown template '{}'. Supported templates: quickstart",
                self.example
            ));
        }

        fs::create_dir_all(&self.output_dir).with_context(|| {
            format!(
                "Failed to create output directory {}",
                self.output_dir.display()
            )
        })?;

        let flow_path = self.output_dir.join("flow.quickstart.yaml");
        let readme_path = self.output_dir.join("FLOW_README.md");

        write_template(
            &flow_path,
            QUICKSTART_FLOW_TEMPLATE,
            self.force,
            "flow template",
        )?;
        write_template(
            &readme_path,
            QUICKSTART_FLOW_README,
            self.force,
            "flow guide",
        )?;

        println!(
            "Initialized script template at {}",
            self.output_dir.display()
        );
        println!("  - {}", flow_path.display());
        println!("  - {}", readme_path.display());
        println!("\nRun with:\n  sui-sandbox script {}", flow_path.display());

        Ok(())
    }
}

impl RunFlowCmd {
    pub async fn execute(
        &self,
        state_file: &Path,
        rpc_url: &str,
        json_output: bool,
        verbose: bool,
    ) -> Result<()> {
        let raw = fs::read_to_string(&self.flow_file)
            .with_context(|| format!("Failed to read flow file {}", self.flow_file.display()))?;
        let flow: FlowFile = serde_yaml::from_str(&raw)
            .with_context(|| format!("Invalid flow YAML in {}", self.flow_file.display()))?;

        if flow.version != 1 {
            return Err(anyhow!(
                "Unsupported flow version {} (expected 1)",
                flow.version
            ));
        }
        if flow.steps.is_empty() {
            return Err(anyhow!("Flow has no steps"));
        }

        if let Some(name) = flow.name.as_deref() {
            println!("Flow: {name}");
        }
        if let Some(description) = flow.description.as_deref() {
            println!("Description: {description}");
        }

        let start = Instant::now();
        let mut reports = Vec::with_capacity(flow.steps.len());

        for (idx, step) in flow.steps.iter().enumerate() {
            let step_name = step.name.clone();
            if step.command.is_empty() {
                return Err(anyhow!("Step {} has empty command", idx + 1));
            }
            if step.command.first().is_some_and(|c| c == "run-flow") {
                return Err(anyhow!(
                    "Step {} uses run-flow recursively; this is not allowed",
                    idx + 1
                ));
            }

            let step_start = Instant::now();
            let display_cmd = step.command.join(" ");
            if !json_output {
                match step_name.as_deref() {
                    Some(name) => println!("[flow:{}:{}] {}", idx + 1, name, display_cmd),
                    None => println!("[flow:{}] {}", idx + 1, display_cmd),
                }
            }

            if self.dry_run {
                reports.push(FlowStepReport {
                    index: idx + 1,
                    name: step_name.clone(),
                    command: step.command.clone(),
                    success: true,
                    exit_code: 0,
                    elapsed_ms: step_start.elapsed().as_millis(),
                    error: None,
                });
                continue;
            }

            let exe = std::env::current_exe().context("Failed to resolve current executable")?;
            let mut cmd = Command::new(exe);
            cmd.arg("--state-file")
                .arg(state_file)
                .arg("--rpc-url")
                .arg(rpc_url);
            if verbose {
                cmd.arg("--verbose");
            }
            cmd.args(&step.command);

            let output = cmd
                .output()
                .with_context(|| format!("Failed to execute step {}", idx + 1))?;

            let ok = output.status.success();
            let code = output.status.code().unwrap_or(-1);
            if !json_output {
                let stdout = String::from_utf8_lossy(&output.stdout);
                let stderr = String::from_utf8_lossy(&output.stderr);
                if !stdout.trim().is_empty() {
                    print!("{}", stdout);
                }
                if !stderr.trim().is_empty() {
                    eprint!("{}", stderr);
                }
            }

            let err = if ok {
                None
            } else {
                Some(format!("step {} failed with exit code {}", idx + 1, code))
            };
            reports.push(FlowStepReport {
                index: idx + 1,
                name: step_name.clone(),
                command: step.command.clone(),
                success: ok,
                exit_code: code,
                elapsed_ms: step_start.elapsed().as_millis(),
                error: err.clone(),
            });

            if !(ok || self.continue_on_error || step.continue_on_error) {
                let report = build_report(
                    &self.flow_file,
                    &flow,
                    self.dry_run,
                    &reports,
                    start.elapsed(),
                );
                if json_output {
                    println!("{}", serde_json::to_string_pretty(&report)?);
                } else {
                    println!(
                        "Flow stopped at step {} (use --continue-on-error to continue)",
                        idx + 1
                    );
                }
                return Err(anyhow!(
                    "flow execution failed at step {} ({})",
                    idx + 1,
                    display_cmd
                ));
            }
        }

        let report = build_report(
            &self.flow_file,
            &flow,
            self.dry_run,
            &reports,
            start.elapsed(),
        );
        if json_output {
            println!("{}", serde_json::to_string_pretty(&report)?);
        } else {
            println!(
                "Flow complete: {}/{} succeeded ({} failed)",
                report.succeeded_steps, report.total_steps, report.failed_steps
            );
        }

        if report.failed_steps > 0 {
            Err(anyhow!(
                "flow completed with {} failed step(s)",
                report.failed_steps
            ))
        } else {
            Ok(())
        }
    }
}

fn build_report(
    flow_file: &Path,
    flow: &FlowFile,
    dry_run: bool,
    reports: &[FlowStepReport],
    elapsed: std::time::Duration,
) -> FlowRunReport {
    let succeeded = reports.iter().filter(|r| r.success).count();
    let failed = reports.len().saturating_sub(succeeded);
    FlowRunReport {
        flow_file: flow_file.display().to_string(),
        name: flow.name.clone(),
        description: flow.description.clone(),
        dry_run,
        total_steps: reports.len(),
        succeeded_steps: succeeded,
        failed_steps: failed,
        elapsed_ms: elapsed.as_millis(),
        steps: reports.to_vec(),
    }
}

struct LoadedFlowContext {
    package_id: String,
    packages_count: usize,
}

#[derive(Debug)]
struct ParsedFlowContext {
    package_id: Option<String>,
    with_deps: bool,
    packages: serde_json::Value,
}

fn prepare_context_data(
    state: &mut SandboxState,
    package_id: &str,
    with_deps: bool,
    verbose: bool,
) -> Result<(FlowContextFile, Vec<String>)> {
    let fetched = fetch_package_with_bytecodes_into_state(state, package_id, with_deps, verbose)
        .with_context(|| format!("Failed to prepare package context for {}", package_id))?;
    let packages: Vec<FlowContextPackage> = fetched
        .packages_fetched
        .iter()
        .map(|pkg| FlowContextPackage {
            address: pkg.address.clone(),
            modules: pkg.modules.clone(),
            bytecodes: pkg.bytecodes.clone().unwrap_or_default(),
        })
        .collect();
    let packages_fetched: Vec<String> = packages.iter().map(|pkg| pkg.address.clone()).collect();
    let context = FlowContextFile {
        version: 2,
        package_id: package_id.to_string(),
        with_deps,
        rpc_url: state.rpc_url.clone(),
        generated_at_ms: now_ms(),
        packages_fetched: packages_fetched.clone(),
        packages: serde_json::to_value(packages)?,
    };
    Ok((context, packages_fetched))
}

fn write_context_file(path: &Path, context: &FlowContextFile, force: bool) -> Result<()> {
    if path.exists() && !force {
        return Err(anyhow!(
            "Refusing to overwrite existing context at {} (pass --force)",
            path.display()
        ));
    }
    if let Some(parent) = path.parent() {
        fs::create_dir_all(parent)
            .with_context(|| format!("Failed to create context directory {}", parent.display()))?;
    }
    fs::write(path, serde_json::to_string_pretty(context)?)
        .with_context(|| format!("Failed to write context {}", path.display()))?;
    Ok(())
}

fn load_context_file_into_state(
    state: &mut SandboxState,
    path: &Path,
    verbose: bool,
) -> Result<LoadedFlowContext> {
    let raw = fs::read_to_string(path)
        .with_context(|| format!("Failed to read context file {}", path.display()))?;
    let value: serde_json::Value = serde_json::from_str(&raw)
        .with_context(|| format!("Invalid context JSON in {}", path.display()))?;
    let parsed = parse_flow_context_value(&value).with_context(|| {
        format!(
            "Invalid context payload in {} (expected flow context wrapper or package map)",
            path.display()
        )
    })?;
    let context_packages = decode_context_packages(&parsed.packages).with_context(|| {
        format!(
            "Failed to decode package payload in context {}",
            path.display()
        )
    })?;

    let mut loaded_count = 0usize;
    if !context_packages.is_empty() {
        loaded_count = load_context_packages_into_state(state, &context_packages)?;
        if verbose {
            eprintln!(
                "[flow] loaded {} packages directly from context {}",
                loaded_count,
                path.display()
            );
        }
    }

    if loaded_count == 0 {
        let package_id = parsed.package_id.as_deref().ok_or_else(|| {
            anyhow!(
                "Context {} has no portable bytecodes and no `package_id` for network refresh",
                path.display()
            )
        })?;
        let fetched = fetch_package_into_state(state, package_id, parsed.with_deps, verbose)
            .with_context(|| {
                format!(
                    "Failed to refresh prepared package context for {}",
                    package_id
                )
            })?;
        loaded_count = fetched.packages_fetched.len();
        if verbose {
            eprintln!(
                "[flow] context had no portable package bytes; refreshed {} package(s) from network",
                loaded_count
            );
        }
    }

    Ok(LoadedFlowContext {
        package_id: parsed
            .package_id
            .unwrap_or_else(|| "<context-packages>".to_string()),
        packages_count: loaded_count,
    })
}

fn parse_flow_context_value(value: &serde_json::Value) -> Result<ParsedFlowContext> {
    match value {
        serde_json::Value::Object(map) => {
            if let Some(packages) = map.get("packages") {
                let package_id = map
                    .get("package_id")
                    .and_then(serde_json::Value::as_str)
                    .map(ToString::to_string);
                let with_deps = map
                    .get("with_deps")
                    .and_then(serde_json::Value::as_bool)
                    .or_else(|| map.get("resolve_deps").and_then(serde_json::Value::as_bool))
                    .unwrap_or(true);
                return Ok(ParsedFlowContext {
                    package_id,
                    with_deps,
                    packages: packages.clone(),
                });
            }

            if looks_like_package_map(map) {
                return Ok(ParsedFlowContext {
                    package_id: None,
                    with_deps: true,
                    packages: value.clone(),
                });
            }

            Err(anyhow!("missing `packages` field"))
        }
        serde_json::Value::Array(_) => Ok(ParsedFlowContext {
            package_id: None,
            with_deps: true,
            packages: value.clone(),
        }),
        _ => Err(anyhow!(
            "unsupported context JSON type (expected object or array)"
        )),
    }
}

fn looks_like_package_map(map: &serde_json::Map<String, serde_json::Value>) -> bool {
    !map.is_empty() && map.keys().all(|key| key.starts_with("0x"))
}

fn decode_context_packages(value: &serde_json::Value) -> Result<Vec<FlowContextPackage>> {
    match value {
        serde_json::Value::Null => Ok(Vec::new()),
        serde_json::Value::Array(_) => {
            serde_json::from_value::<Vec<FlowContextPackage>>(value.clone())
                .context("array `packages` payload is invalid")
        }
        serde_json::Value::Object(map) => {
            // Package map shape: {"0x..": ["base64..."]}.
            let mut out = Vec::with_capacity(map.len());
            for (address, encoded_modules) in map {
                let entries = encoded_modules.as_array().ok_or_else(|| {
                    anyhow!("package {} in map payload must be an array", address)
                })?;
                let mut modules = Vec::with_capacity(entries.len());
                let mut bytecodes = Vec::with_capacity(entries.len());
                for (idx, value) in entries.iter().enumerate() {
                    let b64 = value.as_str().ok_or_else(|| {
                        anyhow!("package {} module #{} is not a string", address, idx)
                    })?;
                    let bytes = base64::engine::general_purpose::STANDARD
                        .decode(b64)
                        .with_context(|| {
                            format!(
                                "invalid base64 bytecode in package {} module #{}",
                                address, idx
                            )
                        })?;
                    let name = inferred_module_name(&bytes, idx);
                    modules.push(name);
                    bytecodes.push(b64.to_string());
                }
                out.push(FlowContextPackage {
                    address: address.clone(),
                    modules,
                    bytecodes,
                });
            }
            Ok(out)
        }
        _ => Err(anyhow!(
            "unsupported `packages` payload type in flow context"
        )),
    }
}

fn load_context_packages_into_state(
    state: &mut SandboxState,
    packages: &[FlowContextPackage],
) -> Result<usize> {
    let mut loaded = 0usize;
    for package in packages {
        if package.bytecodes.is_empty() {
            continue;
        }
        let address = AccountAddress::from_hex_literal(&package.address)
            .with_context(|| format!("invalid package address in context: {}", package.address))?;
        let mut decoded_modules = Vec::with_capacity(package.bytecodes.len());
        for (idx, encoded) in package.bytecodes.iter().enumerate() {
            let bytes = base64::engine::general_purpose::STANDARD
                .decode(encoded)
                .with_context(|| {
                    format!(
                        "invalid base64 bytecode for {} module #{} in context",
                        package.address, idx
                    )
                })?;
            let name = package
                .modules
                .get(idx)
                .cloned()
                .unwrap_or_else(|| inferred_module_name(&bytes, idx));
            decoded_modules.push((name, bytes));
        }
        if decoded_modules.is_empty() {
            continue;
        }
        state.add_package(address, decoded_modules);
        loaded += 1;
    }
    Ok(loaded)
}

fn inferred_module_name(bytes: &[u8], idx: usize) -> String {
    CompiledModule::deserialize_with_defaults(bytes)
        .ok()
        .map(|module| module.self_id().name().to_string())
        .unwrap_or_else(|| format!("module_{}", idx))
}

fn now_ms() -> u64 {
    SystemTime::now()
        .duration_since(UNIX_EPOCH)
        .unwrap_or_default()
        .as_millis() as u64
}

fn default_flow_context_path(package_id: &str) -> PathBuf {
    let trimmed = package_id.trim();
    let no_prefix = trimmed.strip_prefix("0x").unwrap_or(trimmed);
    let short = if no_prefix.is_empty() {
        "package".to_string()
    } else {
        no_prefix.chars().take(20).collect::<String>()
    };
    sandbox_home()
        .join("flow_contexts")
        .join(format!("flow_context.{short}.json"))
}

fn write_template(path: &Path, contents: &str, force: bool, label: &str) -> Result<()> {
    if path.exists() && !force {
        return Err(anyhow!(
            "Refusing to overwrite existing {} at {} (pass --force)",
            label,
            path.display()
        ));
    }
    fs::write(path, contents).with_context(|| format!("Failed to write {}", path.display()))?;
    Ok(())
}

const QUICKSTART_FLOW_TEMPLATE: &str = r#"version: 1
name: quickstart
steps:
  - name: show-status
    command: ["status"]
  - name: publish-fixture
    command:
      [
        "publish",
        "tests/fixture/build/fixture",
        "--bytecode-only",
        "--address",
        "fixture=0x100",
      ]
  - name: list-packages
    command: ["view", "packages"]
"#;

const QUICKSTART_FLOW_README: &str = r#"# Flow Quickstart

This directory was scaffolded by `sui-sandbox init --example quickstart`.

## Run

```bash
sui-sandbox script flow.quickstart.yaml
```

## Notes

- Flow version is pinned to `version: 1`.
- Each step executes exactly one `sui-sandbox` command.
- `command` is a YAML string array (argv style), not shell text.
"#;

#[cfg(test)]
mod tests {
    use super::{
        build_walrus_client, parse_checkpoint_spec, parse_flow_context_value, FlowCli,
        WalrusArchiveNetwork,
    };
    use clap::Parser;
    use serde_json::json;

    #[test]
    fn parses_flow_prepare() {
        let parsed = FlowCli::try_parse_from([
            "flow",
            "prepare",
            "--package-id",
            "0x2",
            "--with-deps",
            "true",
        ]);
        assert!(parsed.is_ok());
    }

    #[test]
    fn parses_flow_replay_with_context() {
        let parsed = FlowCli::try_parse_from([
            "flow",
            "replay",
            "At8M8D7QoW3HHXUBHHvrsdhko8hEDdLAeqkZBjNSKFk2",
            "--context",
            "/tmp/ctx.json",
            "--checkpoint",
            "239615926",
            "--source",
            "walrus",
        ]);
        assert!(parsed.is_ok());
    }

    #[test]
    fn parses_flow_replay_with_discover_latest() {
        let parsed = FlowCli::try_parse_from([
            "flow",
            "replay",
            "--package-id",
            "0x2",
            "--discover-latest",
            "5",
            "--source",
            "walrus",
        ]);
        assert!(parsed.is_ok());
    }

    #[test]
    fn parses_flow_run() {
        let parsed = FlowCli::try_parse_from([
            "flow",
            "run",
            "--package-id",
            "0x2",
            "--digest",
            "At8M8D7QoW3HHXUBHHvrsdhko8hEDdLAeqkZBjNSKFk2",
            "--checkpoint",
            "239615926",
            "--source",
            "walrus",
        ]);
        assert!(parsed.is_ok());
    }

    #[test]
    fn parses_flow_run_with_discover_latest() {
        let parsed = FlowCli::try_parse_from([
            "flow",
            "run",
            "--package-id",
            "0x2",
            "--discover-latest",
            "5",
            "--source",
            "walrus",
        ]);
        assert!(parsed.is_ok());
    }

    #[test]
    fn parses_flow_discover() {
        let parsed = FlowCli::try_parse_from([
            "flow",
            "discover",
            "--latest",
            "5",
            "--package-id",
            "0x2",
            "--limit",
            "50",
        ]);
        assert!(parsed.is_ok());
    }

    #[test]
    fn parses_flow_discover_with_custom_walrus_overrides() {
        let parsed = FlowCli::try_parse_from([
            "flow",
            "discover",
            "--latest",
            "5",
            "--package-id",
            "0x2",
            "--walrus-network",
            "testnet",
            "--walrus-caching-url",
            "https://example-caching.invalid",
            "--walrus-aggregator-url",
            "https://example-aggregator.invalid",
        ]);
        assert!(parsed.is_ok());
    }

    #[test]
    fn rejects_partial_custom_walrus_endpoint_pair() {
        let err = build_walrus_client(
            WalrusArchiveNetwork::Mainnet,
            Some("https://example-caching.invalid"),
            None,
        )
        .expect_err("missing aggregator should fail");
        assert!(err
            .to_string()
            .contains("provide both --walrus-caching-url"));
    }

    #[test]
    fn accepts_full_custom_walrus_endpoint_pair() {
        let client = build_walrus_client(
            WalrusArchiveNetwork::Mainnet,
            Some("https://example-caching.invalid"),
            Some("https://example-aggregator.invalid"),
        )
        .expect("custom pair should construct client");
        let _ = client;
    }

    #[test]
    fn parses_checkpoint_range_spec() {
        let checkpoints = parse_checkpoint_spec("239615920..239615923").expect("range parse");
        assert_eq!(
            checkpoints,
            vec![239615920, 239615921, 239615922, 239615923]
        );
    }

    #[test]
    fn parses_checkpoint_list_spec() {
        let checkpoints = parse_checkpoint_spec("5, 3,5,7").expect("list parse");
        assert_eq!(checkpoints, vec![3, 5, 7]);
    }

    #[test]
    fn rejects_inverted_checkpoint_range() {
        let err = parse_checkpoint_spec("20..10").expect_err("inverted range should fail");
        assert!(err.to_string().contains("end must be >= start"));
    }

    #[test]
    fn parses_python_v1_context_wrapper() {
        let value = json!({
            "version": 1,
            "package_id": "0x2",
            "resolve_deps": true,
            "generated_at_ms": 0,
            "packages": {
                "0x2": []
            }
        });
        let parsed = parse_flow_context_value(&value).expect("python context should parse");
        assert_eq!(parsed.package_id.as_deref(), Some("0x2"));
        assert!(parsed.with_deps);
        assert!(parsed.packages.get("0x2").is_some());
    }

    #[test]
    fn parses_direct_package_map_context() {
        let value = json!({
            "0x2": []
        });
        let parsed = parse_flow_context_value(&value).expect("package map context should parse");
        assert_eq!(parsed.package_id, None);
        assert!(parsed.with_deps);
        assert!(parsed.packages.get("0x2").is_some());
    }

    #[test]
    fn rejects_non_context_object() {
        let value = json!({
            "version": 1
        });
        let err = parse_flow_context_value(&value).expect_err("invalid object should fail");
        assert!(err.to_string().contains("missing `packages` field"));
    }
}
