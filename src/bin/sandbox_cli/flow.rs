//! Generic package->replay context commands.
//!
//! Canonical command: `context` (alias: `flow`).

use anyhow::{anyhow, Context, Result};
use clap::{ArgAction, Args, Parser, Subcommand, ValueEnum};
use serde_json::json;
use std::path::PathBuf;

use super::fetch::fetch_package_into_state;
use super::replay::{FetchStrategy, ReplayCmd, ReplayHydrationArgs, ReplayProfile, ReplaySource};
use super::SandboxState;
use sui_sandbox_core::checkpoint_discovery::{
    build_walrus_client as core_build_walrus_client,
    discover_checkpoint_targets as core_discover_checkpoint_targets,
    resolve_replay_target_from_discovery as core_resolve_replay_target_from_discovery,
    DiscoverOutput as CoreDiscoverOutput, WalrusArchiveNetwork as CoreWalrusArchiveNetwork,
};
use sui_transport::walrus::WalrusClient;

mod context_io;
use context_io::{
    default_flow_context_path, load_context_file_into_state, prepare_context_data,
    write_context_file,
};

#[derive(Parser, Debug)]
#[command(about = "Generic two-step package/replay context flow (flow alias)")]
pub struct FlowCli {
    #[command(subcommand)]
    command: FlowSubcommand,
}

#[derive(Subcommand, Debug)]
enum FlowSubcommand {
    /// Prepare a reusable package context (fetch package + deps)
    Prepare(FlowPrepareCmd),
    /// Replay a transaction with optional prepared context
    Replay(FlowReplayCmd),
    /// Run prepare + replay in one command
    Run(FlowRunCmd),
    /// Discover replay-ready digests + packages from checkpoints
    Discover(FlowDiscoverCmd),
}

#[derive(Args, Debug)]
pub struct FlowPrepareCmd {
    /// Root package id to prepare
    #[arg(long = "package-id")]
    pub package_id: String,

    /// Also fetch transitive dependencies (default: true)
    #[arg(long = "with-deps", default_value_t = true, action = ArgAction::Set)]
    pub with_deps: bool,

    /// Output context JSON path
    #[arg(long)]
    pub output: Option<PathBuf>,

    /// Overwrite existing context file
    #[arg(long, default_value_t = false)]
    pub force: bool,
}

#[derive(Args, Debug)]
pub struct FlowReplayCmd {
    /// Transaction digest to replay
    pub digest: Option<String>,

    /// Optional context file generated by `context prepare` (or `flow prepare`)
    #[arg(long)]
    pub context: Option<PathBuf>,

    /// Optional package id to fetch before replay (if --context is not provided)
    #[arg(long = "package-id")]
    pub package_id: Option<String>,

    /// Also fetch transitive dependencies when using --package-id (default: true)
    #[arg(long = "with-deps", default_value_t = true, action = ArgAction::Set)]
    pub with_deps: bool,

    /// Optional checkpoint override (recommended for walrus source)
    #[arg(long)]
    pub checkpoint: Option<u64>,

    /// Auto-discover a digest from latest N checkpoints (requires --context or --package-id)
    #[arg(long, conflicts_with_all = ["digest", "state_json", "checkpoint"])]
    pub discover_latest: Option<u64>,

    /// Walrus archive network used for --discover-latest
    #[arg(long, value_enum, default_value = "mainnet")]
    pub walrus_network: WalrusArchiveNetwork,

    /// Override Walrus caching endpoint (requires --walrus-aggregator-url)
    #[arg(long)]
    pub walrus_caching_url: Option<String>,

    /// Override Walrus aggregator endpoint (requires --walrus-caching-url)
    #[arg(long)]
    pub walrus_aggregator_url: Option<String>,

    /// Optional state JSON for deterministic custom replay input data
    #[arg(long = "state-json")]
    pub state_json: Option<PathBuf>,

    /// Replay hydration source
    #[arg(long, value_enum, default_value = "hybrid")]
    pub source: ReplaySource,

    /// Runtime defaults profile (tunes fallback and transport behavior)
    #[arg(long, value_enum, default_value = "balanced")]
    pub profile: ReplayProfile,

    /// Fetch strategy for dynamic field children during replay
    #[arg(long, value_enum, default_value = "full")]
    pub fetch_strategy: FetchStrategy,

    /// Allow fallback hydration paths when data is missing
    #[arg(long = "allow-fallback", default_value_t = true, action = ArgAction::Set)]
    pub allow_fallback: bool,

    /// Prefetch depth for dynamic fields
    #[arg(long, default_value_t = 3)]
    pub prefetch_depth: usize,

    /// Prefetch limit per dynamic-field parent
    #[arg(long, default_value_t = 200)]
    pub prefetch_limit: usize,

    /// Disable dynamic-field prefetch
    #[arg(long, default_value_t = false)]
    pub no_prefetch: bool,

    /// Auto-inject system objects (Clock/Random) when missing
    #[arg(long, default_value_t = true, action = ArgAction::Set)]
    pub auto_system_objects: bool,

    /// Compare local replay against on-chain effects
    #[arg(long, default_value_t = false)]
    pub compare: bool,

    /// Hydration-only mode (skip VM execution and print replay-state summary)
    #[arg(long, default_value_t = false)]
    pub analyze_only: bool,

    /// VM-only mode (disable fallback paths)
    #[arg(long, default_value_t = false)]
    pub vm_only: bool,

    /// Reconcile dynamic-field effects when on-chain lists omit them
    #[arg(long, default_value_t = true, action = ArgAction::Set)]
    pub reconcile_dynamic_fields: bool,

    /// Synthesize placeholder inputs when replay fails on missing objects
    #[arg(long, default_value_t = false)]
    pub synthesize_missing: bool,

    /// Allow dynamic-field reads to synthesize placeholder values when missing
    #[arg(long, default_value_t = false)]
    pub self_heal_dynamic_fields: bool,

    /// Timeout in seconds for gRPC object fetches
    #[arg(long, default_value_t = 30)]
    pub grpc_timeout_secs: u64,

    /// Local replay cache path (used when --source local)
    #[arg(long)]
    pub cache_dir: Option<PathBuf>,

    /// Fail command when replay output indicates mismatch/failure
    #[arg(long, default_value_t = false)]
    pub strict: bool,
}

#[derive(Args, Debug)]
pub struct FlowRunCmd {
    /// Root package id to prepare
    #[arg(long = "package-id")]
    pub package_id: String,

    /// Transaction digest to replay (optional when --state-json has a single state)
    #[arg(long)]
    pub digest: Option<String>,

    /// Also fetch transitive dependencies (default: true)
    #[arg(long = "with-deps", default_value_t = true, action = ArgAction::Set)]
    pub with_deps: bool,

    /// Optional path to persist context JSON (portable for later --context replay)
    #[arg(long = "context-out")]
    pub context_out: Option<PathBuf>,

    /// Overwrite existing context file when --context-out is used
    #[arg(long, default_value_t = false)]
    pub force: bool,

    /// Optional checkpoint override (recommended for walrus source)
    #[arg(long)]
    pub checkpoint: Option<u64>,

    /// Auto-discover a digest from latest N checkpoints for --package-id
    #[arg(long, conflicts_with_all = ["digest", "state_json", "checkpoint"])]
    pub discover_latest: Option<u64>,

    /// Walrus archive network used for --discover-latest
    #[arg(long, value_enum, default_value = "mainnet")]
    pub walrus_network: WalrusArchiveNetwork,

    /// Override Walrus caching endpoint (requires --walrus-aggregator-url)
    #[arg(long)]
    pub walrus_caching_url: Option<String>,

    /// Override Walrus aggregator endpoint (requires --walrus-caching-url)
    #[arg(long)]
    pub walrus_aggregator_url: Option<String>,

    /// Optional state JSON for deterministic custom replay input data
    #[arg(long = "state-json")]
    pub state_json: Option<PathBuf>,

    /// Replay hydration source
    #[arg(long, value_enum, default_value = "hybrid")]
    pub source: ReplaySource,

    /// Runtime defaults profile (tunes fallback and transport behavior)
    #[arg(long, value_enum, default_value = "balanced")]
    pub profile: ReplayProfile,

    /// Fetch strategy for dynamic field children during replay
    #[arg(long, value_enum, default_value = "full")]
    pub fetch_strategy: FetchStrategy,

    /// Allow fallback hydration paths when data is missing
    #[arg(long = "allow-fallback", default_value_t = true, action = ArgAction::Set)]
    pub allow_fallback: bool,

    /// Prefetch depth for dynamic fields
    #[arg(long, default_value_t = 3)]
    pub prefetch_depth: usize,

    /// Prefetch limit per dynamic-field parent
    #[arg(long, default_value_t = 200)]
    pub prefetch_limit: usize,

    /// Disable dynamic-field prefetch
    #[arg(long, default_value_t = false)]
    pub no_prefetch: bool,

    /// Auto-inject system objects (Clock/Random) when missing
    #[arg(long, default_value_t = true, action = ArgAction::Set)]
    pub auto_system_objects: bool,

    /// Compare local replay against on-chain effects
    #[arg(long, default_value_t = false)]
    pub compare: bool,

    /// Hydration-only mode (skip VM execution and print replay-state summary)
    #[arg(long, default_value_t = false)]
    pub analyze_only: bool,

    /// VM-only mode (disable fallback paths)
    #[arg(long, default_value_t = false)]
    pub vm_only: bool,

    /// Reconcile dynamic-field effects when on-chain lists omit them
    #[arg(long, default_value_t = true, action = ArgAction::Set)]
    pub reconcile_dynamic_fields: bool,

    /// Synthesize placeholder inputs when replay fails on missing objects
    #[arg(long, default_value_t = false)]
    pub synthesize_missing: bool,

    /// Allow dynamic-field reads to synthesize placeholder values when missing
    #[arg(long, default_value_t = false)]
    pub self_heal_dynamic_fields: bool,

    /// Timeout in seconds for gRPC object fetches
    #[arg(long, default_value_t = 30)]
    pub grpc_timeout_secs: u64,

    /// Local replay cache path (used when --source local)
    #[arg(long)]
    pub cache_dir: Option<PathBuf>,

    /// Fail command when replay output indicates mismatch/failure
    #[arg(long, default_value_t = false)]
    pub strict: bool,
}

#[derive(Args, Debug)]
pub struct FlowDiscoverCmd {
    /// Checkpoint spec: single (239615926), range (239615900..239615926), or list (239615900,239615910)
    #[arg(long, conflicts_with = "latest")]
    pub checkpoint: Option<String>,

    /// Scan latest N checkpoints (auto-discovers tip)
    #[arg(long, conflicts_with = "checkpoint")]
    pub latest: Option<u64>,

    /// Optional package filter (only include transactions touching this package)
    #[arg(long = "package-id")]
    pub package_id: Option<String>,

    /// Include framework packages (0x1/0x2/0x3) in results
    #[arg(long, default_value_t = false)]
    pub include_framework: bool,

    /// Max matching transactions to return
    #[arg(long, default_value_t = 200)]
    pub limit: usize,

    /// Walrus archive network for checkpoint discovery
    #[arg(long, value_enum, default_value = "mainnet")]
    pub walrus_network: WalrusArchiveNetwork,

    /// Override Walrus caching endpoint (requires --walrus-aggregator-url too)
    #[arg(long)]
    pub walrus_caching_url: Option<String>,

    /// Override Walrus aggregator endpoint (requires --walrus-caching-url too)
    #[arg(long)]
    pub walrus_aggregator_url: Option<String>,
}

#[derive(Debug, Clone, Copy, ValueEnum)]
pub enum WalrusArchiveNetwork {
    Mainnet,
    Testnet,
}

impl From<WalrusArchiveNetwork> for CoreWalrusArchiveNetwork {
    fn from(value: WalrusArchiveNetwork) -> Self {
        match value {
            WalrusArchiveNetwork::Mainnet => CoreWalrusArchiveNetwork::Mainnet,
            WalrusArchiveNetwork::Testnet => CoreWalrusArchiveNetwork::Testnet,
        }
    }
}

type FlowDiscoverOutput = CoreDiscoverOutput;

#[derive(Debug, Clone, PartialEq, Eq)]
struct FlowReplayRunOptions {
    source: ReplaySource,
    cache_dir: Option<PathBuf>,
    allow_fallback: bool,
    prefetch_depth: usize,
    prefetch_limit: usize,
    no_prefetch: bool,
    auto_system_objects: bool,
    profile: ReplayProfile,
    fetch_strategy: FetchStrategy,
    vm_only: bool,
    strict: bool,
    compare: bool,
    analyze_only: bool,
    reconcile_dynamic_fields: bool,
    synthesize_missing: bool,
    self_heal_dynamic_fields: bool,
    grpc_timeout_secs: u64,
}

impl FlowReplayRunOptions {
    fn into_replay_cmd(
        self,
        digest: Option<String>,
        checkpoint: Option<u64>,
        state_json: Option<PathBuf>,
    ) -> ReplayCmd {
        ReplayCmd {
            digest,
            hydration: ReplayHydrationArgs {
                source: self.source,
                cache_dir: self.cache_dir,
                allow_fallback: self.allow_fallback,
                prefetch_depth: self.prefetch_depth,
                prefetch_limit: self.prefetch_limit,
                no_prefetch: self.no_prefetch,
                auto_system_objects: self.auto_system_objects,
            },
            profile: self.profile,
            vm_only: self.vm_only,
            strict: self.strict,
            compare: self.compare,
            analyze_only: self.analyze_only,
            verbose: false,
            fetch_strategy: self.fetch_strategy,
            reconcile_dynamic_fields: self.reconcile_dynamic_fields,
            synthesize_missing: self.synthesize_missing,
            self_heal_dynamic_fields: self.self_heal_dynamic_fields,
            grpc_timeout_secs: self.grpc_timeout_secs,
            checkpoint: checkpoint.map(|value| value.to_string()),
            state_json,
            export_state: None,
            latest: None,
        }
    }
}

impl From<&FlowReplayCmd> for FlowReplayRunOptions {
    fn from(value: &FlowReplayCmd) -> Self {
        Self {
            source: value.source,
            cache_dir: value.cache_dir.clone(),
            allow_fallback: value.allow_fallback,
            prefetch_depth: value.prefetch_depth,
            prefetch_limit: value.prefetch_limit,
            no_prefetch: value.no_prefetch,
            auto_system_objects: value.auto_system_objects,
            profile: value.profile,
            fetch_strategy: value.fetch_strategy,
            vm_only: value.vm_only,
            strict: value.strict,
            compare: value.compare,
            analyze_only: value.analyze_only,
            reconcile_dynamic_fields: value.reconcile_dynamic_fields,
            synthesize_missing: value.synthesize_missing,
            self_heal_dynamic_fields: value.self_heal_dynamic_fields,
            grpc_timeout_secs: value.grpc_timeout_secs,
        }
    }
}

impl From<&FlowRunCmd> for FlowReplayRunOptions {
    fn from(value: &FlowRunCmd) -> Self {
        Self {
            source: value.source,
            cache_dir: value.cache_dir.clone(),
            allow_fallback: value.allow_fallback,
            prefetch_depth: value.prefetch_depth,
            prefetch_limit: value.prefetch_limit,
            no_prefetch: value.no_prefetch,
            auto_system_objects: value.auto_system_objects,
            profile: value.profile,
            fetch_strategy: value.fetch_strategy,
            vm_only: value.vm_only,
            strict: value.strict,
            compare: value.compare,
            analyze_only: value.analyze_only,
            reconcile_dynamic_fields: value.reconcile_dynamic_fields,
            synthesize_missing: value.synthesize_missing,
            self_heal_dynamic_fields: value.self_heal_dynamic_fields,
            grpc_timeout_secs: value.grpc_timeout_secs,
        }
    }
}

impl FlowCli {
    pub async fn execute(
        &self,
        state: &mut SandboxState,
        json_output: bool,
        verbose: bool,
    ) -> Result<()> {
        match &self.command {
            FlowSubcommand::Prepare(cmd) => cmd.execute(state, json_output, verbose).await,
            FlowSubcommand::Replay(cmd) => cmd.execute(state, json_output, verbose).await,
            FlowSubcommand::Run(cmd) => cmd.execute(state, json_output, verbose).await,
            FlowSubcommand::Discover(cmd) => cmd.execute(json_output).await,
        }
    }
}

impl FlowPrepareCmd {
    pub(crate) async fn execute(
        &self,
        state: &mut SandboxState,
        json_output: bool,
        verbose: bool,
    ) -> Result<()> {
        let output_path = self
            .output
            .clone()
            .unwrap_or_else(|| default_flow_context_path(&self.package_id));

        let (context, packages_fetched) =
            prepare_context_data(state, &self.package_id, self.with_deps, verbose)?;
        write_context_file(&output_path, &context, self.force)?;

        if json_output {
            println!(
                "{}",
                serde_json::to_string_pretty(&json!({
                    "success": true,
                    "context_path": output_path,
                    "context_metadata": {
                        "version": context.version,
                        "package_id": context.package_id,
                        "with_deps": context.with_deps,
                        "rpc_url": context.rpc_url,
                        "generated_at_ms": context.generated_at_ms,
                    },
                    "packages_fetched_count": packages_fetched.len(),
                }))?
            );
        } else {
            println!("Flow context prepared:");
            println!("  package_id:   {}", self.package_id);
            println!("  with_deps:    {}", self.with_deps);
            println!("  packages:     {}", packages_fetched.len());
            println!("  context_path: {}", output_path.display());
            println!(
                "\nNext:\n  sui-sandbox context replay <DIGEST> --context {} --checkpoint <CP>",
                output_path.display()
            );
        }
        Ok(())
    }
}

impl FlowReplayCmd {
    pub(crate) async fn execute(
        &self,
        state: &mut SandboxState,
        json_output: bool,
        verbose: bool,
    ) -> Result<()> {
        if self.context.is_some() && self.package_id.is_some() {
            return Err(anyhow!(
                "Provide either --context or --package-id, not both"
            ));
        }

        let mut prepared_package: Option<(String, usize)> = None;
        if let Some(path) = self.context.as_ref() {
            let loaded = load_context_file_into_state(state, path, verbose)?;
            prepared_package = Some((loaded.package_id, loaded.packages_count));
        } else if let Some(package_id) = self.package_id.as_ref() {
            let fetched = fetch_package_into_state(state, package_id, self.with_deps, verbose)
                .with_context(|| format!("Failed to prefetch package {}", package_id))?;
            prepared_package = Some((package_id.clone(), fetched.packages_fetched.len()));
        }

        if !json_output {
            if let Some((pkg, count)) = prepared_package.as_ref() {
                println!("Prepared package context: {} ({} packages)", pkg, count);
            }
        }

        let (effective_digest, effective_checkpoint) = resolve_replay_target(
            self.digest.as_deref(),
            self.state_json.as_ref(),
            self.checkpoint,
            self.discover_latest,
            prepared_package.as_ref().map(|(pkg, _)| pkg.as_str()),
            self.walrus_network,
            self.walrus_caching_url.as_deref(),
            self.walrus_aggregator_url.as_deref(),
        )?;

        if !json_output {
            if let (Some(window), Some(digest), Some(checkpoint)) = (
                self.discover_latest,
                effective_digest.as_deref(),
                effective_checkpoint,
            ) {
                println!(
                    "Auto-discovered replay target: digest={} checkpoint={} (latest window: {})",
                    digest, checkpoint, window
                );
            }
        }

        let replay_options = FlowReplayRunOptions::from(self);
        let replay = replay_options.into_replay_cmd(
            effective_digest,
            effective_checkpoint,
            self.state_json.clone(),
        );

        replay.execute(state, json_output, verbose).await
    }
}

impl FlowRunCmd {
    pub(crate) async fn execute(
        &self,
        state: &mut SandboxState,
        json_output: bool,
        verbose: bool,
    ) -> Result<()> {
        let (effective_digest, effective_checkpoint) = resolve_replay_target(
            self.digest.as_deref(),
            self.state_json.as_ref(),
            self.checkpoint,
            self.discover_latest,
            Some(self.package_id.as_str()),
            self.walrus_network,
            self.walrus_caching_url.as_deref(),
            self.walrus_aggregator_url.as_deref(),
        )?;

        let (context, packages_fetched) =
            prepare_context_data(state, &self.package_id, self.with_deps, verbose)?;
        let context_path = if let Some(path) = self.context_out.as_ref() {
            write_context_file(path, &context, self.force)?;
            Some(path.display().to_string())
        } else {
            None
        };

        if !json_output {
            println!(
                "Prepared package context: {} ({} packages)",
                self.package_id,
                packages_fetched.len()
            );
            if let Some(path) = context_path.as_deref() {
                println!("Context written: {}", path);
            }
            if let (Some(window), Some(digest), Some(checkpoint)) = (
                self.discover_latest,
                effective_digest.as_deref(),
                effective_checkpoint,
            ) {
                println!(
                    "Auto-discovered replay target: digest={} checkpoint={} (latest window: {})",
                    digest, checkpoint, window
                );
            }
        }

        let replay_options = FlowReplayRunOptions::from(self);
        let replay = replay_options.into_replay_cmd(
            effective_digest,
            effective_checkpoint,
            self.state_json.clone(),
        );

        replay.execute(state, json_output, verbose).await
    }
}

impl FlowDiscoverCmd {
    pub(crate) async fn execute(&self, json_output: bool) -> Result<()> {
        let walrus = build_walrus_client(
            self.walrus_network,
            self.walrus_caching_url.as_deref(),
            self.walrus_aggregator_url.as_deref(),
        )?;
        let output = discover_flow_targets(
            &walrus,
            self.checkpoint.as_deref(),
            self.latest,
            self.package_id.as_deref(),
            self.include_framework,
            self.limit,
        )?;

        if json_output {
            println!("{}", serde_json::to_string_pretty(&output)?);
        } else {
            println!("Discovery summary:");
            println!("  checkpoints_scanned: {}", output.checkpoints_scanned);
            println!("  transactions_scanned: {}", output.transactions_scanned);
            println!("  ptbs_scanned: {}", output.ptbs_scanned);
            println!("  matches: {}", output.matches);
            if let Some(filter) = output.package_filter.as_deref() {
                println!("  package_filter: {}", filter);
            }
            if output.truncated {
                println!("  truncated: yes (increase --limit to see more)");
            }
            if output.targets.is_empty() {
                println!("No matching transactions found.");
            } else {
                println!("\nTargets:");
                for target in &output.targets {
                    println!(
                        "  cp={} digest={} sender={} packages={} calls={}",
                        target.checkpoint,
                        target.digest,
                        target.sender,
                        target.package_ids.join(","),
                        target.move_calls.len()
                    );
                }
            }
        }
        Ok(())
    }
}

#[allow(clippy::too_many_arguments)]
fn resolve_replay_target(
    digest: Option<&str>,
    state_json: Option<&PathBuf>,
    checkpoint: Option<u64>,
    discover_latest: Option<u64>,
    discover_package_id: Option<&str>,
    walrus_network: WalrusArchiveNetwork,
    walrus_caching_url: Option<&str>,
    walrus_aggregator_url: Option<&str>,
) -> Result<(Option<String>, Option<u64>)> {
    let walrus = build_walrus_client(walrus_network, walrus_caching_url, walrus_aggregator_url)?;
    core_resolve_replay_target_from_discovery(
        digest,
        checkpoint,
        state_json.is_some(),
        discover_latest,
        discover_package_id,
        &walrus,
    )
    .map_err(|err| {
        let message = err.to_string();
        if message == "digest cannot be empty" {
            anyhow!("--digest cannot be empty")
        } else if message
            == "provide digest, state_file, or discover_latest for replay target selection"
        {
            anyhow!("Provide --digest, --state-json, or --discover-latest for replay target selection")
        } else if message == "discover_package_id is required when discover_latest is set" {
            anyhow!(
                "--discover-latest requires package context; pass --package-id or --context with package_id"
            )
        } else {
            err
        }
    })
}

fn discover_flow_targets(
    walrus: &WalrusClient,
    checkpoint_spec: Option<&str>,
    latest: Option<u64>,
    package_id: Option<&str>,
    include_framework: bool,
    limit: usize,
) -> Result<FlowDiscoverOutput> {
    core_discover_checkpoint_targets(
        walrus,
        checkpoint_spec,
        latest,
        package_id,
        include_framework,
        limit,
    )
}

#[cfg(test)]
fn parse_checkpoint_spec(spec: &str) -> Result<Vec<u64>> {
    sui_sandbox_core::checkpoint_discovery::parse_checkpoint_spec(spec)
}

fn build_walrus_client(
    network: WalrusArchiveNetwork,
    caching_url: Option<&str>,
    aggregator_url: Option<&str>,
) -> Result<WalrusClient> {
    core_build_walrus_client(network.into(), caching_url, aggregator_url).map_err(|err| {
        let message = err.to_string();
        if message.contains("provide both walrus_caching_url and walrus_aggregator_url") {
            anyhow!("provide both --walrus-caching-url and --walrus-aggregator-url for custom endpoints")
        } else {
            err
        }
    })
}

#[cfg(test)]
mod tests {
    use super::{build_walrus_client, parse_checkpoint_spec, FlowCli, WalrusArchiveNetwork};
    use super::{
        FetchStrategy, FlowReplayCmd, FlowReplayRunOptions, FlowRunCmd, ReplayProfile, ReplaySource,
    };
    use clap::Parser;
    use serde_json::json;
    use std::path::PathBuf;
    use sui_sandbox_core::context_contract::parse_context_payload;

    #[test]
    fn parses_flow_prepare() {
        let parsed = FlowCli::try_parse_from([
            "flow",
            "prepare",
            "--package-id",
            "0x2",
            "--with-deps",
            "true",
        ]);
        assert!(parsed.is_ok());
    }

    #[test]
    fn parses_flow_replay_with_context() {
        let parsed = FlowCli::try_parse_from([
            "flow",
            "replay",
            "At8M8D7QoW3HHXUBHHvrsdhko8hEDdLAeqkZBjNSKFk2",
            "--context",
            "/tmp/ctx.json",
            "--checkpoint",
            "239615926",
            "--source",
            "walrus",
        ]);
        assert!(parsed.is_ok());
    }

    #[test]
    fn parses_flow_replay_with_discover_latest() {
        let parsed = FlowCli::try_parse_from([
            "flow",
            "replay",
            "--package-id",
            "0x2",
            "--discover-latest",
            "5",
            "--source",
            "walrus",
        ]);
        assert!(parsed.is_ok());
    }

    #[test]
    fn parses_flow_run() {
        let parsed = FlowCli::try_parse_from([
            "flow",
            "run",
            "--package-id",
            "0x2",
            "--digest",
            "At8M8D7QoW3HHXUBHHvrsdhko8hEDdLAeqkZBjNSKFk2",
            "--checkpoint",
            "239615926",
            "--source",
            "walrus",
        ]);
        assert!(parsed.is_ok());
    }

    #[test]
    fn parses_flow_run_with_discover_latest() {
        let parsed = FlowCli::try_parse_from([
            "flow",
            "run",
            "--package-id",
            "0x2",
            "--discover-latest",
            "5",
            "--source",
            "walrus",
        ]);
        assert!(parsed.is_ok());
    }

    #[test]
    fn parses_flow_discover() {
        let parsed = FlowCli::try_parse_from([
            "flow",
            "discover",
            "--latest",
            "5",
            "--package-id",
            "0x2",
            "--limit",
            "50",
        ]);
        assert!(parsed.is_ok());
    }

    #[test]
    fn parses_flow_discover_with_custom_walrus_overrides() {
        let parsed = FlowCli::try_parse_from([
            "flow",
            "discover",
            "--latest",
            "5",
            "--package-id",
            "0x2",
            "--walrus-network",
            "testnet",
            "--walrus-caching-url",
            "https://example-caching.invalid",
            "--walrus-aggregator-url",
            "https://example-aggregator.invalid",
        ]);
        assert!(parsed.is_ok());
    }

    #[test]
    fn rejects_partial_custom_walrus_endpoint_pair() {
        let err = build_walrus_client(
            WalrusArchiveNetwork::Mainnet,
            Some("https://example-caching.invalid"),
            None,
        )
        .expect_err("missing aggregator should fail");
        assert!(err
            .to_string()
            .contains("provide both --walrus-caching-url"));
    }

    #[test]
    fn accepts_full_custom_walrus_endpoint_pair() {
        let client = build_walrus_client(
            WalrusArchiveNetwork::Mainnet,
            Some("https://example-caching.invalid"),
            Some("https://example-aggregator.invalid"),
        )
        .expect("custom pair should construct client");
        let _ = client;
    }

    #[test]
    fn parses_checkpoint_range_spec() {
        let checkpoints = parse_checkpoint_spec("239615920..239615923").expect("range parse");
        assert_eq!(
            checkpoints,
            vec![239615920, 239615921, 239615922, 239615923]
        );
    }

    #[test]
    fn parses_checkpoint_list_spec() {
        let checkpoints = parse_checkpoint_spec("5, 3,5,7").expect("list parse");
        assert_eq!(checkpoints, vec![3, 5, 7]);
    }

    #[test]
    fn rejects_inverted_checkpoint_range() {
        let err = parse_checkpoint_spec("20..10").expect_err("inverted range should fail");
        assert!(err.to_string().contains("end must be >= start"));
    }

    #[test]
    fn parses_python_v1_context_wrapper() {
        let value = json!({
            "version": 1,
            "package_id": "0x2",
            "resolve_deps": true,
            "generated_at_ms": 0,
            "packages": {
                "0x2": []
            }
        });
        let parsed = parse_context_payload(&value).expect("python context should parse");
        assert_eq!(parsed.package_id.as_deref(), Some("0x2"));
        assert!(parsed.with_deps);
        assert_eq!(parsed.packages.len(), 1);
        assert_eq!(parsed.packages[0].address, "0x2");
    }

    #[test]
    fn parses_python_v2_context_wrapper() {
        let value = json!({
            "version": 2,
            "package_id": "0x2",
            "with_deps": true,
            "generated_at_ms": 0,
            "packages": [
                {
                    "address": "0x2",
                    "modules": [],
                    "bytecodes": []
                }
            ]
        });
        let parsed = parse_context_payload(&value).expect("python v2 context should parse");
        assert_eq!(parsed.package_id.as_deref(), Some("0x2"));
        assert!(parsed.with_deps);
        assert_eq!(parsed.packages.len(), 1);
        assert_eq!(parsed.packages[0].address, "0x2");
    }

    #[test]
    fn parses_direct_package_map_context() {
        let value = json!({
            "0x2": []
        });
        let parsed = parse_context_payload(&value).expect("package map context should parse");
        assert_eq!(parsed.package_id, None);
        assert!(parsed.with_deps);
        assert_eq!(parsed.packages.len(), 1);
        assert_eq!(parsed.packages[0].address, "0x2");
    }

    #[test]
    fn rejects_non_context_object() {
        let value = json!({
            "version": 1
        });
        let err = parse_context_payload(&value).expect_err("invalid object should fail");
        assert!(err.to_string().contains("missing `packages` field"));
    }

    #[test]
    fn replay_and_run_map_identical_replay_options() {
        let replay = FlowReplayCmd {
            digest: Some("At8M8D7QoW3HHXUBHHvrsdhko8hEDdLAeqkZBjNSKFk2".to_string()),
            context: Some(PathBuf::from("/tmp/context.json")),
            package_id: None,
            with_deps: true,
            checkpoint: Some(239_615_926),
            discover_latest: None,
            walrus_network: WalrusArchiveNetwork::Mainnet,
            walrus_caching_url: None,
            walrus_aggregator_url: None,
            state_json: Some(PathBuf::from("/tmp/state.json")),
            source: ReplaySource::Walrus,
            profile: ReplayProfile::Fast,
            fetch_strategy: FetchStrategy::Eager,
            allow_fallback: false,
            prefetch_depth: 7,
            prefetch_limit: 123,
            no_prefetch: true,
            auto_system_objects: false,
            compare: true,
            analyze_only: true,
            vm_only: true,
            reconcile_dynamic_fields: false,
            synthesize_missing: true,
            self_heal_dynamic_fields: true,
            grpc_timeout_secs: 77,
            cache_dir: Some(PathBuf::from("/tmp/cache")),
            strict: true,
        };
        let run = FlowRunCmd {
            package_id: "0x2".to_string(),
            digest: replay.digest.clone(),
            with_deps: replay.with_deps,
            context_out: None,
            force: false,
            checkpoint: replay.checkpoint,
            discover_latest: replay.discover_latest,
            walrus_network: replay.walrus_network,
            walrus_caching_url: replay.walrus_caching_url.clone(),
            walrus_aggregator_url: replay.walrus_aggregator_url.clone(),
            state_json: replay.state_json.clone(),
            source: replay.source,
            profile: replay.profile,
            fetch_strategy: replay.fetch_strategy,
            allow_fallback: replay.allow_fallback,
            prefetch_depth: replay.prefetch_depth,
            prefetch_limit: replay.prefetch_limit,
            no_prefetch: replay.no_prefetch,
            auto_system_objects: replay.auto_system_objects,
            compare: replay.compare,
            analyze_only: replay.analyze_only,
            vm_only: replay.vm_only,
            reconcile_dynamic_fields: replay.reconcile_dynamic_fields,
            synthesize_missing: replay.synthesize_missing,
            self_heal_dynamic_fields: replay.self_heal_dynamic_fields,
            grpc_timeout_secs: replay.grpc_timeout_secs,
            cache_dir: replay.cache_dir.clone(),
            strict: replay.strict,
        };

        let from_replay = FlowReplayRunOptions::from(&replay);
        let from_run = FlowReplayRunOptions::from(&run);
        assert_eq!(from_replay, from_run);
    }
}
